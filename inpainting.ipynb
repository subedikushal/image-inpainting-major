{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchsummary import summary\n",
    "from celeb import CelebDataset, CelebDatasetNew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 5 \n",
    "num_epochs = 20 \n",
    "learning_rate = 3e-4 #better is 3e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset initialization\n",
    "# transform = transforms.Compose([transforms.PILToTensor(),transforms.Lambda(lambda x: x / 255.0), transforms.Resize([178,178], antialias=True)])\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Resize([178,178], antialias=True)])\n",
    "\n",
    "train_dataset = CelebDatasetNew(\n",
    "    split='train', transform=transform)\n",
    "\n",
    "test_dataset = CelebDatasetNew(\n",
    "    split='test', transform=transform)\n",
    "\n",
    "val_dataset = CelebDatasetNew(\n",
    "    split='val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, True, num_workers=7)\n",
    "test_loader = DataLoader(test_dataset, batch_size, False, num_workers=7)\n",
    "val_loader = DataLoader(val_dataset, batch_size, False, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/subedikushal/project/major/celeb.py\", line 138, in __getitem__\n    inp_image = io.imread(inp_name)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/skimage/io/_io.py\", line 53, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 205, in call_plugin\n    return func(*args, **kwargs)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/skimage/io/_plugins/imageio_plugin.py\", line 11, in imread\n    out = np.asarray(imageio_imread(*args, **kwargs))\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/v3.py\", line 53, in imread\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/core/imopen.py\", line 113, in imopen\n    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/core/request.py\", line 247, in __init__\n    self._parse_uri(uri)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/core/request.py\", line 407, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\nFileNotFoundError: No such file: '/home/subedikushal/project/major/trainthick/traininput/6381.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# check dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[0;32m----> 3\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m inp, target \u001b[38;5;241m=\u001b[39m samples\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(inp\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/subedikushal/project/major/celeb.py\", line 138, in __getitem__\n    inp_image = io.imread(inp_name)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/skimage/io/_io.py\", line 53, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 205, in call_plugin\n    return func(*args, **kwargs)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/skimage/io/_plugins/imageio_plugin.py\", line 11, in imread\n    out = np.asarray(imageio_imread(*args, **kwargs))\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/v3.py\", line 53, in imread\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/core/imopen.py\", line 113, in imopen\n    request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/core/request.py\", line 247, in __init__\n    self._parse_uri(uri)\n  File \"/home/subedikushal/.local/lib/python3.10/site-packages/imageio/core/request.py\", line 407, in _parse_uri\n    raise FileNotFoundError(\"No such file: '%s'\" % fn)\nFileNotFoundError: No such file: '/home/subedikushal/project/major/trainthick/traininput/6381.png'\n"
     ]
    }
   ],
   "source": [
    "# check dataset\n",
    "examples = iter(train_loader)\n",
    "samples = next(examples)\n",
    "inp, target = samples\n",
    "print(inp.shape)\n",
    "print(inp[0])\n",
    "print(target.shape)\n",
    "\n",
    "for k in range(0, 6, 2):\n",
    "    i = inp[k].permute((1, 2, 0))\n",
    "    plt.subplot(6, 2, k+1)\n",
    "    plt.imshow(i)\n",
    "    o = target[k].permute((1, 2, 0))\n",
    "    plt.subplot(6, 2, k+2)\n",
    "    plt.imshow(o)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), \n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "\n",
    "        # down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                # output = s * (n-1) + k- 2*p\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature,kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2,feature))\n",
    "        \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "            concat_skip = torch.cat((skip_connection, x), dim = 1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET(3,3).to(device)\n",
    "#summary(model,(3,178,178))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        inputs = F.sigmoid(inputs)\n",
    "        targets = F.sigmoid(targets)\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses= {}\n",
    "val_losses = {}\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for input_images,target_images in train_loader:\n",
    "        input_images = input_images.to(device)\n",
    "        target_images = target_images.to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = model(input_images)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, target_images)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    train_losses[epoch] = loss\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for input_images,target_images in val_loader:\n",
    "            input_images = input_images.to(device)\n",
    "            target_images = target_images.to(device)\n",
    "            \n",
    "            \n",
    "            outputs = model(input_images)\n",
    "            \n",
    "            # compute training reconstruction loss\n",
    "            val_loss = criterion(outputs, target_images)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            loss += val_loss.item()\n",
    "        loss = loss / len(val_loader)\n",
    "        val_losses[epoch] = loss\n",
    "\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch, num_epochs, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the current date as a string in the \"YYYY-MM-DD\" format\n",
    "formatted_date = current_datetime.strftime(\"%d-%m-%Y(%H-%M)\")\n",
    "\n",
    "import json\n",
    "with open(f'trainlosses_{formatted_date}.json', 'w') as fp:\n",
    "    json.dump(train_losses, fp)\n",
    "\n",
    "with open(f'vallosses_{formatted_date}.json', 'w') as fp:\n",
    "    json.dump(val_losses, fp)\n",
    "\n",
    "torch.save(model.state_dict(), f'{formatted_date}.pth')\n",
    "print(\"Model Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./unet_model_saved/05-12-2023(18-43)-10e-b5-mse.pth\"))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    h,w = 178,178\n",
    "    examples = iter(test_loader)\n",
    "    samples, label = next(examples)\n",
    "\n",
    "    samples = samples.to(device)\n",
    "    \n",
    "    outputs = model(samples)\n",
    "\n",
    "\n",
    "    print(outputs.shape)\n",
    "    print(outputs)\n",
    "    rows = 3\n",
    "    cols = 3\n",
    "    for i in range(1,rows*cols,cols):\n",
    "        one_label = label[i%batch_size].reshape(3,h,h).permute(1,2,0)\n",
    "        one_label = one_label.cpu().numpy()\n",
    "        one_output = outputs[i%batch_size].reshape(3,h,h).permute(1,2,0)\n",
    "        one_output = one_output.cpu().numpy()\n",
    "        one_sample = samples[i%batch_size].reshape(3,h,h).permute(1,2,0)\n",
    "        one_sample = one_sample.cpu().numpy()\n",
    "\n",
    "        print(one_output.shape)\n",
    "        # input\n",
    "        plt.subplot(rows,cols,i)\n",
    "        if i == 1:\n",
    "            plt.title(\"Input\")\n",
    "        plt.imshow(one_sample)\n",
    "        #output\n",
    "        plt.subplot(rows,cols,i+1)\n",
    "        if i == 1:\n",
    "            plt.title(\"Output\")\n",
    "        plt.imshow(one_output)\n",
    "        # ground truth\n",
    "        plt.subplot(rows,cols,i+2)\n",
    "\n",
    "        if i == 1:\n",
    "            plt.title(\"Ground Truth\")\n",
    "        plt.imshow(one_label)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.05,\n",
    "                        right=0.9,\n",
    "                        top=0.9,\n",
    "                        wspace=0.4,\n",
    "                        hspace=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
